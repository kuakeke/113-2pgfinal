# -*- coding: utf-8 -*-
"""æœŸæœ«å°ˆæ¡ˆ.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16NJb8ceyk0BLuPQDt-nE96YXYiXm4uMZ
"""

import streamlit as st
import pandas as pd
import numpy as np
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
import plotly.express as px

st.set_page_config(page_title="å­¸ç¿’è©•é‡åˆ†æžå·¥å…·", layout="wide")
st.title("ðŸ“Š å­¸ç¿’è©•é‡è¨ˆç®—æ©Ÿ")

st.markdown("ä¸Šå‚³å­¸ç”Ÿä½œç­”çš„ Google Sheetï¼ˆåŒ¯å‡ºæˆ CSVï¼‰ï¼Œæ¯åˆ—ç‚ºé¡Œè™Ÿï¼Œæ¯æ¬„ç‚ºå­¸ç”Ÿç­”é¡Œç´€éŒ„ï¼ˆ0 æˆ– 1ï¼‰")

uploaded_file = st.file_uploader("è«‹ä¸Šå‚³ CSV æª”æ¡ˆ", type="csv")

if uploaded_file:
    df = pd.read_csv(uploaded_file)
    df = df.set_index("question")
    st.subheader("åŽŸå§‹è³‡æ–™é è¦½")
    st.dataframe(df)

    df_t = df.T.copy()
    df_t["score"] = df_t.sum(axis=1)

    sorted_students = df_t.sort_values("score", ascending=False)
    n = len(sorted_students)
    group_size = round(n * 0.27)
    high_group = sorted_students.head(group_size).drop(columns="score")
    low_group = sorted_students.tail(group_size).drop(columns="score")

    high_correct_rate = high_group.T.mean(axis=1)
    low_correct_rate = low_group.T.mean(axis=1)
    difficulty = ((high_correct_rate + low_correct_rate) / 2).round(2)

    def get_difficulty_label(p):
        if p >= 0.80:
            return "æ¥µå®¹æ˜“"
        elif 0.60 <= p < 0.80:
            return "å®¹æ˜“"
        elif 0.40 <= p < 0.60:
            return "é›£æ˜“é©ä¸­"
        elif 0.20 <= p < 0.40:
            return "å›°é›£"
        else:
            return "æ¥µå›°é›£"

    P = difficulty.apply(get_difficulty_label)

    high_correct_counts = high_group.T.sum(axis=1)
    low_correct_counts = low_group.T.sum(axis=1)
    discrimination = ((high_correct_counts - low_correct_counts) / (n / 2)).round(2)

    def get_discrimination_label(d):
        if d >= 0.40:
            return "æ¥µä½³çš„è©¦é¡Œ"
        elif 0.30 <= d < 0.40:
            return "å°šå¯çš„è©¦é¡Œï¼Œå¯èƒ½éœ€è¦ç¨åŠ æ”¹é€²"
        elif 0.20 <= d < 0.30:
            return "ä¸ä½³çš„è©¦é¡Œï¼Œå¿…é ˆåŠ ä»¥æ”¹é€²ï¼Œæˆ–æ£„å»"
        else:
            return "æ¥µå·®çš„è©¦é¡Œï¼Œæ‡‰æ£„å»"

    evaluation = discrimination.apply(get_discrimination_label)

    d_df = pd.DataFrame({
        "é«˜åˆ†çµ„ç­”å°çŽ‡": high_correct_rate,
        "é«˜åˆ†çµ„ç­”å°æ•¸": high_correct_counts,
        "ä½Žåˆ†çµ„ç­”å°çŽ‡": low_correct_rate,
        "ä½Žåˆ†çµ„ç­”å°æ•¸": low_correct_counts,
        "é›£åº¦": difficulty,
        "é‘‘åˆ¥åº¦": discrimination,
        "é›£æ˜“è©•é‘‘": P,
        "é‘‘åˆ¥è©•é‘‘": evaluation
    })

    st.subheader("ðŸ“‹ è©¦é¡Œåˆ†æžå ±è¡¨")
    st.dataframe(d_df)

    # èšé¡žèˆ‡è¦–è¦ºåŒ–
    d_df = d_df.reset_index().rename(columns={"index": "question"})
    kmeans = KMeans(n_clusters=4, random_state=42)
    d_df['åˆ†é¡žç¾¤çµ„'] = kmeans.fit_predict(d_df[["é›£åº¦", "é‘‘åˆ¥åº¦"]])
    pca = PCA(n_components=2)
    components = pca.fit_transform(d_df[["é›£åº¦", "é‘‘åˆ¥åº¦"]])
    d_df['ä¸»æˆåˆ†1'] = components[:, 0]
    d_df['ä¸»æˆåˆ†2'] = components[:, 1]

    st.subheader("ðŸ“Œ èšé¡žè¦–è¦ºåŒ–ï¼šé›£åº¦ vs é‘‘åˆ¥åº¦")
    fig = px.scatter(
        d_df,
        x="é›£åº¦",
        y="é‘‘åˆ¥åº¦",
        color="åˆ†é¡žç¾¤çµ„",
        text="question",
        title="è©¦é¡Œåˆ†é¡žåˆ†æžåœ–ï¼ˆé›£åº¦èˆ‡é‘‘åˆ¥åº¦ï¼‰",
        hover_data=["é«˜åˆ†çµ„ç­”å°çŽ‡", "ä½Žåˆ†çµ„ç­”å°çŽ‡"]
    )
    fig.update_traces(textposition='top center')
    st.plotly_chart(fig, use_container_width=True)

    csv = d_df.to_csv(index=False).encode('utf-8-sig')
    st.download_button(
        label="ðŸ“¥ ä¸‹è¼‰åˆ†æžçµæžœ CSV",
        data=csv,
        file_name='è©¦é¡Œåˆ†æžçµæžœ.csv',
        mime='text/csv'
    )